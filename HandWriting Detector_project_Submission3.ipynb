{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a1a6b1-c47b-4af2-844a-5f23d76ac3cb",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th><h1>CS 3368</h1><h2>Introduction to Artificial Intelligence</h2>\n",
    "        <h1 style=\"color:maroon;\">Team Project Assignment</h1>\n",
    "        <h2 style=\"color:maroon;\">Third Submission</h2></th>\n",
    "        <th><img src=\"https://www.ttu.edu/traditions/images/raiderstatue.jpg\" width=225 height=116 /></th>\n",
    "        <th><p>Texas Tech University Matador Song</p>\n",
    "            <p>Fight, Matadors, for Tech!<br>\n",
    "                Songs of love we'll sing to thee,<br>\n",
    "                Bear our banners far and wide.<br>\n",
    "                Ever to be our pride,<br>\n",
    "                Fearless champions ever be.<br>\n",
    "                Stand on heights of victory.<br>\n",
    "                Strive for honor evermore.<br>\n",
    "                Long live the Matadors!</p>\n",
    "                <p>Music by Harry Lemaire, words by R.C. Marshall</p></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb7f8fb-882d-4098-adea-e82a20733aa5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color:darkgoldenrod\">Enter the Team Name Here</h1>\n",
    "\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Sagar Basavaraju</bf></h4></li>\n",
    "<li style=\"color:maroon\"><h4><bf>Team member first name and last name</bf></h4></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f507e5be-5fe6-415b-afa0-ed6e1f22f27c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color:darkgoldenrod\">AI Problem</h1>\n",
    "\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>What is the problem on which the team worked for this submission?</bf></h4></li>\n",
    "    <ul>\n",
    "        <li> The main problem I was involved with are improving techniques with standardization of the data and improving convergence patterns within the data.\n",
    "         </li>\n",
    "        <li> Providing key performance metrics for accuracy,precision recall and F1 score and create a structured loop for validation for multiple epochs and improved the learning rate and data augmentation. </li>\n",
    "        <li> Added visualization models to view loss precision and help in analyzing the learning rate of my model. </li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Is it the same or a different problem than the problem(s) proposed in the proposal or the second submission?  If changes in scope or other changes to the problem have been made since the proposal or second submission, please explain here.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li> THis problem previously defined is similar to what we originally defined but score and added visuals helps programmer and model ouput and train with correct and accurate metrics.</li>\n",
    "        <li>...</li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Please summarize here what advances and lessons learned the team made in solving the problem for this submission.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Advances:</h5>\n",
    "            <ul>\n",
    "                <li>Advance...</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><h5>Lessons Learned:</h5>\n",
    "            <ul>\n",
    "                <li>Lesson Learned...</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1939f91c-d08c-43f1-8290-9f6e0507e92a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color:darkgoldenrod\">What other ideas, models, approaches, and/or helpful suggestions have you found since the last team submission related to solving the AI problem or similar problems by others?</h1>\n",
    "\n",
    "<hr>\n",
    "<h2 style=\"color: teal\">From Journal/Conference Papers</h2>\n",
    "\n",
    "<p>Papers from previous submissions should not be listed here.</p>\n",
    "\n",
    "<p>Journal and conference papers report on research to solve problems.  They do not necessarily have tutorial instructions, but they do report on many ideas that were used in the past, the ideas used by the authors to solve the problem in the paper, and ideas for future research.  They can help you narrow down quickly promising ideas to use to solve a problem.  Examples of ideas are using A-star search and developing a modified version of A-star search to reduce the state space by sampling the actions.  Normal data processing, such as cleaning data, or normal steps to solve a problem would not be the ideas for which you are searching as you read the paper.</p>\n",
    "<p>Another thing that papers have are results that you can use to compare to your solution so you can see if your solution approach has merit.  If your solution does not do as well as solutions reported in the papers, use the papers to find ideas to improve the solution that you have.</p>\n",
    "<p>You want to look for papers listed in the Scopus database available through the <a href=\"https://ttu-primo.hosted.exlibrisgroup.com/primo-explore/dbsearch?vid=01TTU\">TTU Library's Website</a>, and enter \"Scopus\" into the search box.  Papers listed in Scopus will be in venues recognized by scholars and the papers you use should have at least 5 citations.  In particular, when reading the papers, look for relationships among the solution ideas, how the authors evaluated their solutions, and what promising ideas the authors think could improve their work.</p>\n",
    "\n",
    "<p>Use <a href=\"https://ieee-dataport.org/sites/default/files/analysis/27/IEEE%20Citation%20Guidelines.pdf\">IEEE</a> or <a href=\"https://www.acm.org/publications/authors/reference-formatting\">ACM</a> format for listing the paper references.  An example is following.</p>\n",
    "<ul>\n",
    "    <li style=\"color:maroon\"><h4><bf>David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot et al. 2018. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science 362, 6419 (2018), 1140-1144.  https://www.science.org/doi/epdf/10.1126/science.aar6404, 4070 citations (Google Scholar), 2276 citations (Scopus).</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Problem:</h5>  How can the AlphaGo Zero algorithm be made a more general algorithm to achieve superhuman performance in many challenging games?</li>\n",
    "        <li><h5>Past Solution Ideas:</h5>  Early chess playing bots (hardware and algorithms to play chess), Deep Blue and subsequent chess-playing programs (high-performance alpha-beta search with many clever heuristics and domain-specific adaptions), AlphaGo Zero algorithm (deep convolutional neural networks trained by reinforcement learning from games of self-play), Computer Shogi Association's Elmo (optimized alpha-beta search with domain-specific adaptations)</li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5>  AlphaZero algorithm (more generic version than AlphaGo Zero, deep neural networks, general purpose RL algorithm and Monte Carlo tree search algorithms)</li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5>  not mentioned but could investigate more RL techniques to create general game-playing systems, find optimizations for AlphaZero to use less memory and search time, apply AlphaZero to complex robotic tasks</li>\n",
    "        <li><h5>Evaluation Ideas:</h5>  Pitted AlphaZero against Stockfish (chess), Elmo (Shogi), and Go (AlphaGo Zero) where AlphaZero turned out to be more efficient in search and could outperform all 3 with sufficient training</li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5>  deep neural networks, reinforcement learning</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Köpf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala, \"PyTorch: An Imperative Style, High-Performance Deep Learning Library,\" in Advances in Neural Information Processing Systems 32 (NeurIPS 2019), Vancouver, Canada, 2019.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Problem:</h5>This problems tradeoffs were vastly between the the different solution and problem outcomes from the performance and different tasks between different deep learning frameworks and evaluating efficiencies and opportunities for growth versus dynamic frameworks that were used like Chainer which was less expensive and faster language  or Dynet/Torch which were Flexible models but had losses in performance issues   </li>\n",
    "        <li><h5>Past Solution Ideas: </h5> There were past frameworks such as TensorFlow which used static computation with optimizations but had limiting in terms of debugging and hard for computer researchers to interact with the program. Chainer/DyNet used different frameworks and were more flexible such as including conditional statements buts slower performances with static graphs that were used.    </li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5> Pytorch use for combatance of flexibility in developing of CNN models and in terms of Scalabilities with computational environments for resource gains and utilizing different models and various data sets, and integrations with pythons platforms and environments used.  </li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5> Have more support for mobile platforms, different techniques in visualization and model frameworks with training set ups and improved cluster usages for large scaled data bases  </li>\n",
    "        <li><h5>Evaluation Ideas:</h5> better training speed in the use of image classification and NLP. Utilizing Cuda framework and more efficient GPU utilization and pythons API and reinforcement learning models.   </li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5> helps in understanding the various configuraions for CNN and fully connected layers and utilizing custome data sets such as kaggle in built in pyTorch and more extended use with creations in additonal layers and accuracy for different model architectures </li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf></bf></h4>[1]F. Sadaf, S. M. Taslim Uddin Raju, and A. Muntakim, “Offline Bangla Handwritten Text Recognition: A Comprehensive Study of Various Deep Learning Approaches,” IEEE Xplore, Dec. 01, 2021. https://ieeexplore.ieee.org/document/9718890\n",
    "‌\n",
    "‌</li>\n",
    "    <ul>\n",
    "        <li><h5>Problem:</h5> The main problem was hcallenging due to the many differences within eachfine grained image styles as the different styles were too casual or subtle to make differences noticable to the person.     </li>\n",
    "        <li><h5>Past Solution Ideas:</h5> Many past solution ideas heavily relied on manual feature extractions such as KNN/Decision trees or SVM algorithms which shows challenges within different visual similarities and through which each model would have a hard time to recognize generalize the data within each extraction.   </li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5> Through the use of CNN's and different textures and features we can focus on each model with distinguishing different writing styles to be easily able to recognize these features. and utilizng diffferent preprocessing and normalization of each model.  </li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5> Look into more deeper netowrks such as ResNet DenseNet and through attention layers focusing on more specalizedd part of the image for classifying them. Utilizing different techniques such as rotations,generalizations and data augmentation to extrpolate hyperparameters and noise.     </li>\n",
    "        <li><h5>Evaluation Ideas:</h5> Evaluation Ideas include using more standardized metrics such as accuracy,precision, and F1 score to balance these datasets. Analyzing mis-classifications within each pattern assesing scalability issues.     </li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5>  The team would like to use more normalization of pixelated values, augmentation and experiment with more deeper CNN's (ResNet,Densenet for feature learning) and incorporating pre-trained models for improved accuracy. </li>\n",
    "    </ul>\n",
    "    <li style=\"color:maroon\">...at least one new paper from a SCOPUS referenced publication per team member</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e750733-0c99-440a-9abc-9fa8da8d722d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2 style=\"color: teal\">From Other Informal Resources</h2>\n",
    "<hr>\n",
    "\n",
    "<p>Informal resources from previous submissions should not be listed here.</p>\n",
    "\n",
    "<p>Other informal resources include work that is not published in journals or conferences, such as blog sites, tutorials, posted software, software package websites, generative AI tools, and past class project reports that are available online.  Such resources may have concrete examples of how to do various solutions and have software packages or resources that can be used in the team's solution.  Such information and resources should be used to enable the team to go further and faster than they could have gone if the team had started from scratch.</p>\n",
    "<hr>\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>[1]“MNIST Handwritten Digit Recognition in PyTorch,” nextjournal.com. https://nextjournal.com/gkoehler/pytorch-mnist\n",
    "‌</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Helpful information/code/ideas/examples:</h5> Utilizing CNN architecture such as extracting different parameter features such as edges and petterns within images also different hues and marks as noise for the model to look out for or ignore would help in visualization. Utilizing Pytorch Max Pooling for downsampling features and reducing computational overloading. Finally establishing more fully connected layers and using nn.CrossEntropyLoss for loss calculation and optimizations such as using Adam or SGD for validation purposes and training of the model.  </li>\n",
    "        <li><h5>What the team would like to use from this resource:</h5> I would love to incorporate from this resource such as batch normalization and dropout. Also use efficient modes of Data loading and loss functions within pytorch such as ADAM or SGD for training our models.  </li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>[1]R. vaishnav, “Handwritten Digit Recognition Using PyTorch, Get 99.5% accuracy in 20 k parameters.,” Medium, Aug. 13, 2020. https://ravivaishnav20.medium.com/handwritten-digit-recognition-using-pytorch-get-99-5-accuracy-in-20-k-parameters-bcb0a2bdfa09 (accessed Nov. 22, 2024).\n",
    "‌</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Helpful information/code/ideas/examples:</h5> Different Techniques such as utilizing 1x1 CNN's and using Global Average pooling phenomen to replace fully connected layers and reduce the hyper parameters and utilizing normalization and CNN layers for better training of those models. Also our team could use the process batch normalization for CNN layers for normalizing training distributions. This resource did give examples of using the 7-layer CNN architecture, data augmentation to each implementation using the MNIST dataset.  </li>\n",
    "        <li><h5>What the team would like to use from this resource:</h5> using pixel normalizations and data augmentation for normalizing data and reducing feature range of values and standarding prcoesses for each pixel value. My team would also benfit from using SGD and momentum for improving learning rates and ensuring model convergence and finally adding in the 1X1 convolutions and global average pooling in design and efficient recognitions to identify patterns within the model.  </li>\n",
    "    </ul>\n",
    "    ...\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa84f4-a1dd-4df8-8fb2-25088b18e92e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color: darkgoldenrod\">Past Plans and Actual Tasks for the Third Project Assignment Submission</h1>\n",
    "\n",
    "<p>The third project assignment submission is the final status report on how far the team has gotten in solving the problem.  Overall, status reports will include but not be limited to items, such as updates to the problem scope, lessons learned, finding more ideas in the conference and journal paper literature as well as informal resources, data sources found, current solution status and performance, comparison of solution to past approaches, software developed and packages used, hardware used, testing, and consideration of new solution approaches.</p>\n",
    "\n",
    "<p>Each team member should catalog the actual work tasks performed for this submission including specfic papers and resources found, AI solution models proposed, preliminary investigative work on a software prototype, researching evaluation strategies for the team's solution, finding needed data files, interviewing experts, solving subproblems, planning, designing, coding, testing, and anything related to helping the team complete the submission well.</p>\n",
    "\n",
    "<p>Tasks should have enough detail to understand clearly and specifically what was done.  For example, rather than say, \"found and wrote up 2 conference papers\", include the authors, such as \"found and wrote up 2 conference papers by Smith et al, 2022, and Breugrand et al, 2019\" so it is clear which papers were contributed to a submission.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Each team member plans to apply an AI solution to the problem and has the following accomplishments and plans:\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"color: maroon\"><bf>Team Member Name</bf></th>\n",
    "        <th style=\"color: maroon\"><bf>Planned Team Member Tasks for Third Submission</bf></th>\n",
    "        <th style=\"color: maroon\"><bf>Actual Team Member Tasks for Third Submission</bf></th>\n",
    "    </tr>\n",
    "    <tr style=\"text-align:left\">\n",
    "        <th>Sagar Basavaraju</th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Review the MNIST Databased and the dataset and review documentation - Week 1 Set Up Keras and pytorch IDE and install specifc libraries such as Pandas,Numpy, and Matplotlib., 2 to 3 hours</li>\n",
    "                <li>Week 2 Set up preprocessing and Normalizing functions to standardize the data and make more efficient changes to avoid discrpencies within the data and Utilizing processes such as Batching,caching and prefetching the loading the data into memory for efficient data retrieval. , 2 to 3 hours</li>\n",
    "                <li>implement Training and testing sets while utilizing a training model to load data and characterize it using convolusional nueral networks, 1 to 2  hour </li>\n",
    "                <li>Define the layers of your CNN model, such as convolutional layers, activation functions (e.g., ReLU), and pooling layers.Week 4 - Fit the model to the training data and specify the number of epochs. 3 to 4 hours </li>\n",
    "                <li>Week 5 : Create a confusion matrix to visualize classification performance. Experiment with different hyperparameters (learning rate, batch size, number of layers) to improve performance. 2 to 3 hours </li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Tasks planned from the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Tasks planned from the proposal submission\n",
    "                    Reviewed the Emnist dataset architecture and set up the python environment for Pytorch and use of Pandas,matplotlib and numpy, also install pip and latest version of python Implement the data loading and preprocessing procedure and traing the model based on features and utilizing a CNN network for acuracy task, time estimate\n",
    "                    Review the recent journal positions and review research papers and select different appropriate layers using the different convolutional layers and activation functions time , 2 to 3 hours</li>\n",
    "                <li>Task was to first set up the python environment made sure python was updated to 3.12 and followed pytorch documentation correctly to allow for downloading of necessary libraries we need for developing our model also installed kaggle to be used for data set retrieval.,1 to 2 hours</li>\n",
    "                <li>Implemented efficient data compatibility with pytorch model and made sure conversion from CSV file to pytorch was efficient.Created a convolusional layer model that extracts key patterns and features from our data set and ReLU and maxpooling to reduce noise and improve model performance. 4 to 6 hours</li>\n",
    "            </ul>\n",
    "            </ul>\n",
    "        </th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks actually done for the third submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Include Proper Loss and Metrics for covering different metrics on loss,precision, and F1 score and proper validation processes for each epoch. Include Validation sets for proper training to prevent overfitting, 2 to 3 hours</li>\n",
    "                <li>Applying Batch Normalization and dropout and increase depth within CNN and improve rate scheduling for handling convergence, 2 hours</li>\n",
    "                <li>Enforce Data Augmentation and add visual plots to evaluate and visualize loss functions for our metrics of our data. 2 to 3 hours </li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            </ul>\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr style=\"text-align:left\">\n",
    "        <th>team member name</th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                <li>task, time estimate</li>\n",
    "                <li>task, time estimate</li>\n",
    "                <li>...</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Tasks planned from the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>task, time estimate</li>\n",
    "                <li>task, time estimate</li>\n",
    "                <li>...</li>\n",
    "            </ul>\n",
    "            </ul>\n",
    "        </th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks actually done for the third submission</bf></li>\n",
    "            <ul>\n",
    "                <li>task, actual time or time estimate</li>\n",
    "                <li>task, actual time or time estimate</li>\n",
    "                <li>...</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            </ul>\n",
    "        </th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f71f4-6357-4057-8c39-5d8a6d7b800c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color: darkgoldenrod\">Current Solution Status</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffa796-2ef5-46fd-bdf7-1d7774298edb",
   "metadata": {},
   "source": [
    "<h2 style=\"color:teal\">What computer hardware, programming language, main software packages, and data files are recommended to be used to run the software for this submission?</h2>\n",
    "    <ul>\n",
    "        <li><h5 style=\"color:maroon\">Computer Hardware</h5> Laptop with possibility of access into HPCC resources : recommended CPU: Atleast Intel I7 and graphics card with CUDA compatibility accepted</li>\n",
    "        <li><h5 style=\"color:maroon\">Programming Language</h5>Atleast Python 3.12.1 or latest vesion </li>\n",
    "        <li><h5 style=\"color:maroon\">Main Software Packages</h5> Pytorch, Keras, TensorFlow, matplotlib,seaborn,numpy,pandas</li>\n",
    "        <li><h5 style=\"color:maroon\">Data</h5> Utilizing kaggle csv files for both train and test files found from kaggle. </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4681706-eda0-4131-9418-1c803a494611",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2 style=\"color: teal\">What is the performance of the team's solutions in comparison with results from journal/conference papers and other informal resources since the last submission?</h2>\n",
    "\n",
    "<p>Comparisons from previous submissions should not be listed here.</p>\n",
    "\n",
    "<p>For the third submission, each team member should plan to add at least one more reference for comparison of performance regardless of how many are given in submission two.  Performance includes but is not limited to the amount of memory consumed, the order of the algorithms used, computation time, number of operations performed, experimental results on various data sets or trials, and measurements, such as precision, recall, accuracy, F-measure, and cluster purity/silouette.  Graphs, such as the ROC curve, precision/recall curve, scatter plots showing the relationship between two attributes, line charts showing model performance at various training points, and bar charts comparing approaches, may also be used.</p>\n",
    "\n",
    "<p>If a direct comparison is not available, try to find a reference that is similar in nature.  In addition, discuss with the course instructors any difficulty you are having in finding references to compare against.  Other ideas include implementing more solutions to compare against each other.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Team Solution - Digit Recognizer</h3>\n",
    "\n",
    "<p>Fill in description of team solution</p>\n",
    "\n",
    "<h4 style=\"color:darkblue\"> Informal Reference : [1]A. Tam, “Handwritten Digit Recognition with LeNet5 Model in PyTorch - MachineLearningMastery.com,” MachineLearningMastery.com, Mar. 07, 2023. https://machinelearningmastery.com/handwritten-digit-recognition-with-lenet5-model-in-pytorch/ (accessed Nov. 22, 2024).\n",
    "‌</h4>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"color: darkgreen\"><bf>Comparison with Reference Solution</bf></th>\n",
    "        <th style=\"color: darkgreen\"><bf>Reasons why the performance of the team's solution is better/same/worse</bf></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>The reference solution included a more of a complexion in structure and architecture of the model with additional features such as ResNet and deeper neural networks acheiving greater accuracy in model training. The reference also included CrossEntropyLoss() functions which when defined helped for analyzes and better represent score cassification and give an accurate probability of each models performance. The reference solution also included important training procedures that enhanced the learning model such as introducing optimizer function,epochs and zero_grad() which helps updata models parameters and help the model converge better.Finally using pooling functions and functions like nn.Dropout() in reducing overfitting of the functions helping reduce noise of the data. </th>\n",
    "        <th>After utilizing data augmentation, incorporating entropyLoss, reducing outisde noise and reduce the effect of disrupting models in-accurate results, and including additional features and metrics such as f1 score and batch normalization/ rate schedulers etc.which helps prevent overfitting and improves on the reference solution. These added benefits, and more visualizations for the each epoch will improve its performance,accuracy and help the model train from within its overall structure.</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "...\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Team Solution - Fill in Descriptive Name</h3>\n",
    "\n",
    "<p>Fill in description of team solution</p>\n",
    "\n",
    "<h4 style=\"color:darkblue\">Paper/Informal Reference</h4>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"color: darkgreen\"><bf>Comparison with Reference Solution</bf></th>\n",
    "        <th style=\"color: darkgreen\"><bf>Reasons why the performance of the team's solution is better/same/worse</bf></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Fill in reference description solution and performance, and comparison between team's solution and the reference's solution</th>\n",
    "        <th>Fill in reasons for the performance differences or lack of differences between the reference and team solutions</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "...\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Discussion/Summary of Solution Results</h3>\n",
    "\n",
    "<p>Please use this section to use items, such as well-labeled graphs and tables, to show a comparison of all team member solutions against each other and with the paper/informal reference solutions, to show a summary of all solution results, and give a discussion of what could be planned to be done for a hypothetical next submission to continue to improve the performance of each team member's solution.</p>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e79bd9-e8dc-4769-b9ab-d709b16918a6",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"color: darkgoldenrod\">Software</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beed320-23a0-4664-9483-b0e626619d81",
   "metadata": {},
   "source": [
    "<p>Please be sure to submit a requirements.txt file so that the instructors can easily run the code in this Jupyter Notebook.  The requirements.txt file should be in the same working directory as the Jupyter Notebook.  Also, please give any special instructions beyond the normal running of code in a Jupyter Notebook, such as where data files should be placed if not in the working directory of this Jupyter Notebook or if some of the installed software packages have additional requirements beyond \"pip install\".</p>\n",
    "\n",
    "<p>Each code cell should have contextually related code, such as a class, function implementing a major algorithm, or a set of short functions that support a larger function in a subsequent cell.  Code cells should also be present to show the performance/evaluation of a solution through well labeled graphs, tables, and/or performance measure values.</p>\n",
    "\n",
    "<p>The code cells also can be organized by each team member's solution.</p>\n",
    "\n",
    "<p>Each major set of related code cells should have the purpose of the code cells, the paper/informal references used (if any) to develop the code in the code cells, the team members who worked on the code cells, and major changes made to the code in the code cells by team members for this submission.  Changes made in a previous submission should not be included.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2 style=\"color: teal\">Are there any special instructions for running the code in this Jupyter Notebook for this submission?</h2>\n",
    "\n",
    "<ul>\n",
    "    <li>make sure python is up to the latest, and pip has been updated succsessfully.</li>\n",
    "    <li>Make sure torch torchvision pandas matplotlib are installed</li>\n",
    "    <li> All data sets have been populated and loaded correctly and install kaggle within python environment and if using the integrated GPU make sure the correct drivers and python are installed correctly.</li>\n",
    "</ul>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e6faba-e744-4216-a5a7-55834d8773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to capture all of the installed packages so far (run by the team to submit with the Jupyter notebook)\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9b9ece-5297-4cb8-a663-7587f16459d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anyio==4.6.2.post1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 1)) (4.6.2.post1)\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 3)) (21.2.0)\n",
      "Requirement already satisfied: arrow==1.3.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: asttokens==2.4.1 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 5)) (2.4.1)\n",
      "Requirement already satisfied: async-lru==2.0.4 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 6)) (2.0.4)\n",
      "Requirement already satisfied: attrs==24.2.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 7)) (24.2.0)\n",
      "Requirement already satisfied: babel==2.16.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 8)) (2.16.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 9)) (4.12.3)\n",
      "Requirement already satisfied: bleach==6.2.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 10)) (6.2.0)\n",
      "Requirement already satisfied: cachetools==5.3.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 11)) (5.3.3)\n",
      "Requirement already satisfied: certifi==2024.8.30 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 12)) (2024.8.30)\n",
      "Requirement already satisfied: cffi==1.17.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 13)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.4.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 14)) (3.4.0)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 15)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 16)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 17)) (1.3.0)\n",
      "Requirement already satisfied: cryptography==43.0.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 18)) (43.0.3)\n",
      "Requirement already satisfied: cycler==0.12.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 19)) (0.12.1)\n",
      "Requirement already satisfied: debugpy==1.8.7 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 20)) (1.8.7)\n",
      "Requirement already satisfied: decorator==5.1.1 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 21)) (5.1.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 22)) (0.7.1)\n",
      "Requirement already satisfied: executing==2.1.0 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 23)) (2.1.0)\n",
      "Requirement already satisfied: fastjsonschema==2.20.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 24)) (2.20.0)\n",
      "Requirement already satisfied: filelock==3.16.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 25)) (3.16.1)\n",
      "Requirement already satisfied: fonttools==4.54.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 26)) (4.54.1)\n",
      "Requirement already satisfied: fqdn==1.5.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 27)) (1.5.1)\n",
      "Requirement already satisfied: fsspec==2024.10.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 28)) (2024.10.0)\n",
      "Requirement already satisfied: google-api-core==2.19.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 29)) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client==2.135.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 30)) (2.135.0)\n",
      "Requirement already satisfied: google-auth==2.31.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 31)) (2.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2==0.2.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 32)) (0.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib==1.2.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 33)) (1.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos==1.63.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 34)) (1.63.2)\n",
      "Requirement already satisfied: greenlet==3.0.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 35)) (3.0.3)\n",
      "Requirement already satisfied: h11==0.14.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 36)) (0.14.0)\n",
      "Requirement already satisfied: html5lib==1.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 37)) (1.1)\n",
      "Requirement already satisfied: httpcore==1.0.6 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 38)) (1.0.6)\n",
      "Requirement already satisfied: httplib2==0.22.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 39)) (0.22.0)\n",
      "Requirement already satisfied: httpx==0.27.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 40)) (0.27.2)\n",
      "Requirement already satisfied: idna==3.10 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 41)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 42)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.29.0 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 43)) (8.29.0)\n",
      "Requirement already satisfied: ipywidgets==8.1.5 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 44)) (8.1.5)\n",
      "Requirement already satisfied: isoduration==20.11.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 45)) (20.11.0)\n",
      "Requirement already satisfied: jedi==0.19.1 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 46)) (0.19.1)\n",
      "Requirement already satisfied: Jinja2==3.1.4 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 47)) (3.1.4)\n",
      "Requirement already satisfied: joblib==1.4.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 48)) (1.4.2)\n",
      "Requirement already satisfied: json5==0.9.25 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 49)) (0.9.25)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 50)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 51)) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2024.10.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 52)) (2024.10.1)\n",
      "Requirement already satisfied: jupyter==1.1.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 53)) (1.1.1)\n",
      "Requirement already satisfied: jupyter-console==6.6.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 54)) (6.6.3)\n",
      "Requirement already satisfied: jupyter-events==0.10.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 55)) (0.10.0)\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 56)) (2.2.5)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 57)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 58)) (5.7.2)\n",
      "Requirement already satisfied: jupyter_server==2.14.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 59)) (2.14.2)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 60)) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab==4.2.5 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 61)) (4.2.5)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 62)) (0.3.0)\n",
      "Requirement already satisfied: jupyterlab_server==2.27.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 63)) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.13 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 64)) (3.0.13)\n",
      "Requirement already satisfied: kaggle==1.6.17 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 65)) (1.6.17)\n",
      "Requirement already satisfied: kiwisolver==1.4.7 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 66)) (1.4.7)\n",
      "Requirement already satisfied: lightning-utilities==0.11.9 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 67)) (0.11.9)\n",
      "Requirement already satisfied: lxml==5.2.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 68)) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 69)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib==3.9.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 70)) (3.9.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 71)) (0.1.7)\n",
      "Requirement already satisfied: mistune==3.0.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 72)) (3.0.2)\n",
      "Requirement already satisfied: mpmath==1.3.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 73)) (1.3.0)\n",
      "Requirement already satisfied: nbclient==0.10.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 74)) (0.10.0)\n",
      "Requirement already satisfied: nbconvert==7.16.4 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 75)) (7.16.4)\n",
      "Requirement already satisfied: nbformat==5.10.4 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 76)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 77)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 78)) (3.4.2)\n",
      "Requirement already satisfied: notebook==7.2.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 79)) (7.2.2)\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 80)) (0.2.4)\n",
      "Requirement already satisfied: numpy==2.1.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 81)) (2.1.3)\n",
      "Requirement already satisfied: oauthlib==3.2.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 82)) (3.2.2)\n",
      "Requirement already satisfied: overrides==7.7.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 83)) (7.7.0)\n",
      "Requirement already satisfied: packaging==24.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 84)) (24.1)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 85)) (2.2.3)\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 86)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.4 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 87)) (0.8.4)\n",
      "Requirement already satisfied: pillow==11.0.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 88)) (11.0.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 89)) (4.3.6)\n",
      "Requirement already satisfied: prometheus_client==0.21.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 90)) (0.21.0)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.48 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 91)) (3.0.48)\n",
      "Requirement already satisfied: proto-plus==1.24.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 92)) (1.24.0)\n",
      "Requirement already satisfied: protobuf==5.27.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 93)) (5.27.2)\n",
      "Requirement already satisfied: psutil==6.1.0 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 94)) (6.1.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 95)) (0.2.3)\n",
      "Requirement already satisfied: pyasn1==0.6.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 96)) (0.6.0)\n",
      "Requirement already satisfied: pyasn1_modules==0.4.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 97)) (0.4.0)\n",
      "Requirement already satisfied: pycparser==2.22 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 98)) (2.22)\n",
      "Requirement already satisfied: pygame==2.5.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 99)) (2.5.2)\n",
      "Requirement already satisfied: Pygments==2.18.0 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 100)) (2.18.0)\n",
      "Requirement already satisfied: pyparsing==3.2.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 101)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 102)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger==2.0.7 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 103)) (2.0.7)\n",
      "Requirement already satisfied: python-slugify==8.0.4 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 104)) (8.0.4)\n",
      "Requirement already satisfied: pytz==2024.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 105)) (2024.2)\n",
      "Requirement already satisfied: pywin32==308 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 106)) (308)\n",
      "Requirement already satisfied: pywinpty==2.0.14 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 107)) (2.0.14)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 108)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 109)) (26.2.0)\n",
      "Requirement already satisfied: referencing==0.35.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 110)) (0.35.1)\n",
      "Requirement already satisfied: requests==2.32.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 111)) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib==2.0.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 112)) (2.0.0)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 113)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 114)) (0.1.1)\n",
      "Requirement already satisfied: rpds-py==0.20.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 115)) (0.20.1)\n",
      "Requirement already satisfied: rsa==4.9 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 116)) (4.9)\n",
      "Requirement already satisfied: scikit-learn==1.5.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 117)) (1.5.2)\n",
      "Requirement already satisfied: scipy==1.14.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 118)) (1.14.1)\n",
      "Requirement already satisfied: seaborn==0.13.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 119)) (0.13.2)\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 120)) (1.8.3)\n",
      "Requirement already satisfied: setuptools==75.3.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 121)) (75.3.0)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 122)) (1.16.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 123)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.6 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 124)) (2.6)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.30 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 125)) (2.0.30)\n",
      "Requirement already satisfied: stack-data==0.6.3 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 126)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 127)) (1.13.1)\n",
      "Requirement already satisfied: terminado==0.18.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 128)) (0.18.1)\n",
      "Requirement already satisfied: text-unidecode==1.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 129)) (1.3)\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 130)) (3.5.0)\n",
      "Requirement already satisfied: tinycss2==1.4.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 131)) (1.4.0)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 132)) (2.5.1)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 133)) (2.5.1)\n",
      "Requirement already satisfied: torchmetrics==1.6.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 134)) (1.6.0)\n",
      "Requirement already satisfied: torchvision==0.20.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 135)) (0.20.1)\n",
      "Requirement already satisfied: tornado==6.4.1 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 136)) (6.4.1)\n",
      "Requirement already satisfied: tqdm==4.66.6 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 137)) (4.66.6)\n",
      "Requirement already satisfied: traitlets==5.14.3 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 138)) (5.14.3)\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20241003 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 139)) (2.9.0.20241003)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 140)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2024.2 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 141)) (2024.2)\n",
      "Requirement already satisfied: uri-template==1.3.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 142)) (1.3.0)\n",
      "Requirement already satisfied: uritemplate==4.1.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 143)) (4.1.1)\n",
      "Requirement already satisfied: urllib3==2.2.3 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 144)) (2.2.3)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in c:\\users\\puttu\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 145)) (0.2.13)\n",
      "Requirement already satisfied: webcolors==24.8.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 146)) (24.8.0)\n",
      "Requirement already satisfied: webencodings==0.5.1 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 147)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.8.0 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 148)) (1.8.0)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.13 in c:\\users\\puttu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 149)) (4.0.13)\n"
     ]
    }
   ],
   "source": [
    "#to install all of the packages in requirements.txt (run by the instructors when grading the notebook)\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298cad8-bed1-4d45-aeb2-e6ce5df3a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages to import to run the code in the Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565039db-a366-44bf-adf9-f5928380d74a",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Descriptive Name</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>fill in the purpose of the code cell block</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>paper/informal reference</li>\n",
    "    <li>...</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Team member name</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>mm/dd/yyyy - major change made for this submission</li>\n",
    "    <li>...</li>\n",
    "</ul>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Team member name</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>mm/dd/yyyy - major change made for this submission</li>\n",
    "    <li>...</li>\n",
    "</ul>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b45c6-a6d2-4dcf-9941-6e15bb2697b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44024dbf-a49d-4901-8d34-cab79c43429c",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Descriptive Name</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>fill in the purpose of the code cell block</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>paper/informal reference</li>\n",
    "    <li>[1]OpenAI, “Introducing ChatGPT,” Openai.com, Nov. 30, 2022. https://openai.com/index/chatgpt/</li>\n",
    "    <li>[1]“torcheval.metrics.functional.multiclass_f1_score — TorchEval main documentation,” Pytorch.org, 2022. https://pytorch.org/torcheval/stable/generated/torcheval.metrics.functional.multiclass_f1_score.html (accessed Nov. 23, 2024).\n",
    "    </li>\n",
    "    <li>[1]GeeksforGeeks, “How to squeeze and unsqueeze a tensor in PyTorch?,” GeeksforGeeks, Mar. 26, 2022. https://www.geeksforgeeks.org/how-to-squeeze-and-unsqueeze-a-tensor-in-pytorch/ (accessed Nov. 23, 2024).\n",
    "‌   </li>\n",
    "    <li>[1]A. Tam, “Handwritten Digit Recognition with LeNet5 Model in PyTorch - MachineLearningMastery.com,” MachineLearningMastery.com, Mar. 07, 2023. https://machinelearningmastery.com/handwritten-digit-recognition-with-lenet5-model-in-pytorch/\n",
    "‌   </li>\n",
    "    <li>[1]“Adam — PyTorch 1.11.0 documentation,” pytorch.org. https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
    "‌ </li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Sagar Basavaraju</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Team member name</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>11/21/2023 - Found 2 informal and 2 formal research articles regarding CNN networks and different applications and precision values regarding how we can analyze predict and validate and better train our current model</li>\n",
    "    <li>Extensively researching of libraries and optimizations bring important metrics such as F1 Score,accuracy. Using differentiating between labeling and unlabeled data and simulating unlabeled data and extensivly using metrics from sklearn and creating y-pred and y-true values and detailed prediction analyzes based on how well support was compared to true labeled data. </li>\n",
    "</ul>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Team member name</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>mm/dd/yyyy - major change made for this submission</li>\n",
    "    <li>...</li>\n",
    "</ul>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3f9cba-98c2-4c51-9a4f-488c07be834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Loss: 153.0509\n",
      "Epoch [2/4], Loss: 41.4978\n",
      "Epoch [3/4], Loss: 29.1041\n",
      "Epoch [4/4], Loss: 24.2825\n",
      "Accuracy if no labels: 0.10%\n",
      "F1-Score if no labels: 0.10%\n",
      "Predictions (first 10): [2, 0, 9, 0, 3, 7, 0, 3, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "import numpy as np\n",
    "# Custom Dataset\n",
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, name, transform=ToTensor(), label_name=\"label\", is_labeled=True):\n",
    "        self.data = pd.read_csv(name)  \n",
    "        self.transform = transform\n",
    "        self.label_name = label_name\n",
    "        self.is_labeled = is_labeled\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pixel_data = self.data.iloc[idx].drop(self.label_name, errors='ignore').values.astype('float32')\n",
    "        scaled_pixel = (pixel_data - pixel_data.min()) / (pixel_data.max() - pixel_data.min())\n",
    "        image = scaled_pixel.reshape(28, 28)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_labeled:\n",
    "            label = int(self.data.iloc[idx][self.label_name])\n",
    "            return image, label\n",
    "        return image\n",
    "\n",
    "# Load Datasets\n",
    "train_dataset = CustomMNISTDataset(name=\"train.csv\", is_labeled=True)\n",
    "test_dataset = CustomMNISTDataset(name=\"test.csv\", is_labeled=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# CNN Model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(64 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Training\n",
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        if len(images.shape) != 4:\n",
    "            images = images.unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Validation\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "correct = 0\n",
    "if test_dataset.is_labeled:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            if len(images.shape) != 4:\n",
    "                images = images.unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            y_pred.extend(predictions.cpu().numpy().tolist())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "        accuracy = accuracy_score(y_true,y_pred)\n",
    "        F1_score = f1_score(y_true,y_pred,average=\"weighted\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"F1-Score: {F1_score:.2f}%\")\n",
    "else:\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            if len(images.shape) != 4:\n",
    "                images = images.unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            y_pred.extend(predictions.cpu().numpy().tolist())\n",
    "    #simulations if labels were provided:\n",
    "    nlabels = np.random.choice(10,len(y_pred)) \n",
    "    accuracy = accuracy_score(nlabels,y_pred)\n",
    "    F1_score = f1_score(nlabels,y_pred,average=\"weighted\")\n",
    "    print(f\"Accuracy if no labels: {accuracy:.2f}%\")\n",
    "    print(f\"F1-Score if no labels: {F1_score:.2f}%\")\n",
    "\n",
    "\n",
    "print(f\"Predictions (first 10): {y_pred[:10]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
